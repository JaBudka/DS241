---
title: "Lab 05 - La Quinta is Spanish for *next to Denny's*, Pt. 2"
subtitle: "Wrangling spatial data"
author: "Joe Skufca"
output: 
  tufte::tufte_html:
    tufte_variant: "envisioned"
    highlight: pygments
    css: ../lab.css
link-citations: yes
---

```{r include=FALSE}
# library(tufte)
# library(knitr)
# options(
#   htmltools.dir.version = FALSE, # for blogdown
#   show.signif.stars = FALSE,     # for regression output
#   digits = 2
#   )
# knitr::opts_chunk$set(eval = FALSE)
```

```{r fig.margin=TRUE, eval=TRUE, echo=FALSE}
# include_graphics("img/mitch-hedgeberg-lqd.jpg")
```

In this lab we revisit the Denny's and La Quinta Inn and Suites data we visualized in the previous lab.

## Getting started

- Go to the course organization on GitHub.

- Find your lab repo.

- In the repo, click on the green **Clone or download** button, select  **Use HTTPS** (this might already be selected by default, and if it is,  you'll see the text **Clone with HTTPS** as in the image below). Click on  the clipboard icon to copy the repo URL.

- Go to RStudio Cloud and into the course workspace. Create a **New Project from Git Repo**. You will need to click on the down arrow next to the **New Project** button to see this option.

- Copy and paste the URL of your assignment repo into the dialog box:

- Hit OK, and you're good to go!

### Packages

In this lab we will use the **tidyverse** and **dsbox** packages.

```{r eval = FALSE}
library(tidyverse) 
library(dsbox) 
```

## The data

The datasets we'll use are called `dennys` and `laquinta` from the **dsbox** package. 


```{r}
states <- read_csv("U:/DataScience/ds241/states.csv")
dn=dennys
lq =laquinta
 nrow(dennys)
 nrow(laquinta)
```

```{r}
fas_foo <- read_csv("U:/DataScience/ds241/FastFoodRestaurants.csv")
fast_food <- fas_foo %>%
  rename(
    state = province
    )
  
# View(fast_food)

# for some absolutely incomprehensible reason you have to reload the files window for this to run.
```


```{r attempt at counting each location}
# fast_food_filter <- fast_food %>%
#   group_by(name) %>%
#   summarise(count = n_distinct(name)) 
# fast_food_filter
```
```{r attempt at filtering just McDonalds}
# fast_food_test <- fast_food %>% filter(name == "McDonald's")
# fast_food_test
```

```{r}
# mcdonalds <- fast_food %>%
#   filter(grepl('mcdonalds', websites) & grepl('Mc', name)) %>%
#   select(latitude, longitude, name, province)
# View(mcdonalds)
```

```{r}
get_chain <- function(fast_food_data, grepl_website, grepl_name){
  data <- fast_food_data %>% 
    filter(grepl(grepl_website, websites) & grepl(grepl_name, name)) %>%
    select(latitude, longitude, name, province)
}
```

Testing our new function 
```{r}
mcdonalds2 <- get_chain(fast_food, 'tacobell', 'Ta')
View(mcdonalds2)
```


```{r}
nrow(mcdonalds2)
```

Need to 

```{r Jackie Trying to group by chain name}
# fast_food_names <- fast_food %>%
#  select(name) %>%
# rbind(fast_food_names, by = "name") %>%
# mutate(
#   test_string = substr(fast_food_names, 1, 6)
# )
# d <- adist(fast_food_names)
# rownames(d)  <- n 
# cl <- hclust(as.dist(d)) 
# plot(cl)
```

# Mark's Lab 5
Step 1:
Get all of lab 5 working, to include creating a function that takes a "state" as input and produces the output dataframe of distinces.
```{r create_function}
map_mindist <- function(which_state) {
#step i
x = which_state

dn_x <- dennys %>%
filter(state == x)



lq_x <- laquinta %>%
filter(state == x)

dn_lq_x <- full_join(dn_x, lq_x, by = "state") %>%
mutate(distance = haversine(longitude.x, latitude.x, longitude.y, latitude.y, round = 1))

dn_lq_x_mindist <- dn_lq_x %>%
group_by(address.x) %>%
summarise(closest = min(distance))

}
```

step 2:
Modify (probably already done in class) so that ... given a state, if creates a dataframe that for each la quinta, it includes distance to nearest dennys.
```{r create_modified_function}
step2_mindist <- function(which_state) {
#step i
x = which_state

dn_x <- dennys %>%
filter(state == x)


lq_x <- laquinta %>%
filter(state == x)

lq_dn_x <- full_join(lq_x, dn_x, by = "state") %>%
mutate(distance = haversine(longitude.x, latitude.x, longitude.y, latitude.y, round = 1))

lq_dn_x_mindist <- lq_dn_x %>%
group_by(address.x) %>%
summarise(closest = min(distance)) %>%
mutate(state = x)


#The below code will help you quickly print visualizations or summary statistics

# summary(dn_lq_x_mindist)
# ggplot(data = dn_lq_x_mindist) +
# geom_dotplot(mapping = aes(x = closest))

}
```


```{r testing}
lq_dn_tx_mindist <- step2_mindist("TX")
# View(lq_dn_tx_mindist)

dn_tx <- dennys %>%
filter(state == "TX")
nrow(dn_tx)num_den = nrow(dn_x)
```



Step 3:
Grab the dataset (available in moodle in "week of 28 Sep" ) for the 10000 US restaurants.

We complete step 3 above

Step 4:
Create a function that takes a "state" as input and produces a dataframe, where there is one observation per "la quinta" and it lists distance to nearest "Restaurant".
```{r}
step4_mindist <- function(which_state) {
#step i
x = which_state

lq_x <- laquinta %>%
filter(state == x)

fast_food_x <- fast_food %>%
  filter(state == x) %>%
  sample_n(nrow(dennys %>% filter(state==x)))

lq_rest_x <- full_join(lq_x, fast_food_x, by = "state") %>%
mutate(distance = haversine(longitude.x, latitude.x, longitude.y, latitude.y, round = 1))

lq_rest_x_mindist <- lq_rest_x %>%
group_by(address.x) %>%
summarise(closest = min(distance)) %>%
mutate(state = x)

}
```


```{r testing}
lq_rest_tx_mindist4 <- step4_mindist("TX")
# View(lq_dn_tx_mindist)

```


Step
    
    